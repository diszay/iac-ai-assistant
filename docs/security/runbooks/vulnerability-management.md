# Vulnerability Management Runbook

## Overview

This runbook provides comprehensive procedures for vulnerability management in the Proxmox AI Infrastructure Assistant environment. It covers vulnerability identification, assessment, prioritization, remediation, and verification processes.

## Vulnerability Management Lifecycle

### 1. Vulnerability Discovery

#### Automated Vulnerability Scanning

```bash
#!/bin/bash
# Automated vulnerability scanning script
# File: /scripts/security/vulnerability_scan.sh

set -euo pipefail

SCAN_DATE=$(date +%Y%m%d_%H%M%S)
SCAN_DIR="/var/log/security/vulnerability_scans"
PROXMOX_HOST="192.168.1.50"

# Create scan directory
mkdir -p "$SCAN_DIR/$SCAN_DATE"
cd "$SCAN_DIR/$SCAN_DATE"

echo "=== Vulnerability Scan Started: $(date) ===" | tee scan.log

# 1. Network vulnerability scan
echo "Running network vulnerability scan..." | tee -a scan.log
nmap --script vuln -oA network_vuln_scan "$PROXMOX_HOST" 2>&1 | tee -a scan.log

# 2. System vulnerability scan (on Proxmox host)
echo "Running system vulnerability scan..." | tee -a scan.log
ssh -i ~/.ssh/proxmox_ai_key -p 2849 root@"$PROXMOX_HOST" "
    # Update package database
    apt update -qq
    
    # Check for security updates
    apt list --upgradable 2>/dev/null | grep -i security > security_updates.txt || true
    
    # Run system vulnerability scan
    if command -v lynis >/dev/null 2>&1; then
        lynis audit system --quiet --log-file lynis_audit.log
    fi
    
    # Check for CVE vulnerabilities
    if command -v cve-check-tool >/dev/null 2>&1; then
        cve-check-tool -c cve_results.xml
    fi
    
    # Docker security scan (if applicable)
    if command -v docker >/dev/null 2>&1; then
        docker run --rm -v /var/run/docker.sock:/var/run/docker.sock \
            aquasec/trivy image --format json --output trivy_results.json proxmox/ve || true
    fi
" 2>&1 | tee -a scan.log

# 3. Application dependency scan
echo "Running application dependency scan..." | tee -a scan.log
cd /home/diszay-claudedev/projects/iac-ai-assistant

# Python dependency vulnerability scan
if command -v safety >/dev/null 2>&1; then
    safety check --json --output "$SCAN_DIR/$SCAN_DATE/python_dependencies.json" 2>&1 | tee -a "$SCAN_DIR/$SCAN_DATE/scan.log" || true
fi

# NPM audit (if Node.js dependencies exist)
if [ -f "package.json" ]; then
    npm audit --json > "$SCAN_DIR/$SCAN_DATE/npm_audit.json" 2>&1 || true
fi

# 4. Container vulnerability scan
echo "Running container vulnerability scan..." | tee -a scan.log
if command -v trivy >/dev/null 2>&1; then
    trivy fs --format json --output "$SCAN_DIR/$SCAN_DATE/filesystem_scan.json" . 2>&1 | tee -a scan.log || true
fi

# 5. Configuration security scan
echo "Running configuration security scan..." | tee -a scan.log
ssh -i ~/.ssh/proxmox_ai_key -p 2849 root@"$PROXMOX_HOST" "
    # SSH configuration check
    sshd -T > sshd_config_test.txt 2>&1 || true
    
    # Firewall configuration check
    iptables -L -n > iptables_rules.txt 2>&1 || true
    
    # File permissions audit
    find /etc -type f -perm /o+w > world_writable_files.txt 2>&1 || true
    find /etc -type f -perm /g+w > group_writable_files.txt 2>&1 || true
" 2>&1 | tee -a scan.log

echo "=== Vulnerability Scan Completed: $(date) ===" | tee -a scan.log

# Generate scan summary
echo "Generating scan summary..." | tee -a scan.log
python3 << 'EOF'
import json
import os
import sys
from datetime import datetime

scan_dir = os.getcwd()
summary = {
    "scan_date": datetime.now().isoformat(),
    "scan_directory": scan_dir,
    "findings": {
        "critical": 0,
        "high": 0,
        "medium": 0,
        "low": 0,
        "info": 0
    },
    "scans_completed": [],
    "scans_failed": []
}

# Process scan results
scan_files = [
    ("network_vuln_scan.nmap", "Network Vulnerability Scan"),
    ("python_dependencies.json", "Python Dependencies Scan"),
    ("npm_audit.json", "NPM Dependencies Scan"),
    ("filesystem_scan.json", "Filesystem Scan")
]

for filename, scan_name in scan_files:
    if os.path.exists(filename):
        summary["scans_completed"].append(scan_name)
        
        # Parse JSON results where applicable
        if filename.endswith('.json'):
            try:
                with open(filename, 'r') as f:
                    data = json.load(f)
                    # Process based on scan type
                    if 'python_dependencies' in filename:
                        vulnerabilities = data.get('vulnerabilities', [])
                        for vuln in vulnerabilities:
                            severity = vuln.get('severity', 'unknown').lower()
                            if severity in summary["findings"]:
                                summary["findings"][severity] += 1
                    elif 'trivy' in filename or 'filesystem' in filename:
                        results = data.get('Results', [])
                        for result in results:
                            vulns = result.get('Vulnerabilities', [])
                            for vuln in vulns:
                                severity = vuln.get('Severity', 'UNKNOWN').lower()
                                if severity in summary["findings"]:
                                    summary["findings"][severity] += 1
            except (json.JSONDecodeError, KeyError) as e:
                print(f"Error processing {filename}: {e}")
    else:
        summary["scans_failed"].append(scan_name)

# Write summary
with open('vulnerability_scan_summary.json', 'w') as f:
    json.dump(summary, f, indent=2)

print(f"Scan Summary:")
print(f"- Critical: {summary['findings']['critical']}")
print(f"- High: {summary['findings']['high']}")
print(f"- Medium: {summary['findings']['medium']}")
print(f"- Low: {summary['findings']['low']}")
print(f"- Info: {summary['findings']['info']}")
EOF

echo "Vulnerability scan completed. Results saved to: $SCAN_DIR/$SCAN_DATE"
```

#### Manual Vulnerability Assessment

**Quarterly Security Review Checklist:**

- [ ] **System Configuration Review**
  - SSH configuration hardening verification
  - Firewall rules effectiveness assessment
  - Service configuration security review
  - User account and permission audit

- [ ] **Network Security Assessment**
  - Network segmentation verification
  - VPN configuration review
  - Network monitoring effectiveness
  - Intrusion detection system status

- [ ] **Application Security Review**
  - Code security analysis
  - Dependency vulnerability assessment
  - Configuration security verification
  - Input validation effectiveness

- [ ] **Infrastructure Security Audit**
  - VM security configuration review
  - Storage encryption verification
  - Backup security assessment
  - Disaster recovery testing

### 2. Vulnerability Assessment and Prioritization

#### Risk Assessment Matrix

```python
#!/usr/bin/env python3
# Vulnerability Risk Assessment Tool
# File: /scripts/security/vulnerability_risk_assessment.py

import json
import sys
from dataclasses import dataclass
from enum import Enum
from typing import List, Dict, Any
from datetime import datetime

class Severity(Enum):
    CRITICAL = "critical"
    HIGH = "high"
    MEDIUM = "medium"
    LOW = "low"
    INFO = "info"

class Exploitability(Enum):
    EASY = "easy"
    MEDIUM = "medium"
    HARD = "hard"

class AssetCriticality(Enum):
    CRITICAL = "critical"  # Proxmox host, production VMs
    HIGH = "high"         # Development VMs, important services
    MEDIUM = "medium"     # Test VMs, non-critical services
    LOW = "low"           # Isolated systems, deprecated services

@dataclass
class Vulnerability:
    cve_id: str
    title: str
    description: str
    severity: Severity
    cvss_score: float
    affected_systems: List[str]
    exploitability: Exploitability
    asset_criticality: AssetCriticality
    remediation_complexity: str
    business_impact: str
    
    def calculate_risk_score(self) -> float:
        """Calculate composite risk score based on multiple factors"""
        # Base score from CVSS
        base_score = self.cvss_score
        
        # Exploitability multiplier
        exploitability_multiplier = {
            Exploitability.EASY: 1.5,
            Exploitability.MEDIUM: 1.2,
            Exploitability.HARD: 0.8
        }
        
        # Asset criticality multiplier
        criticality_multiplier = {
            AssetCriticality.CRITICAL: 2.0,
            AssetCriticality.HIGH: 1.5,
            AssetCriticality.MEDIUM: 1.0,
            AssetCriticality.LOW: 0.5
        }
        
        # Calculate final risk score
        risk_score = (base_score * 
                     exploitability_multiplier[self.exploitability] * 
                     criticality_multiplier[self.asset_criticality])
        
        return min(risk_score, 10.0)  # Cap at 10.0
    
    def get_priority_level(self) -> str:
        """Determine priority level based on risk score"""
        risk_score = self.calculate_risk_score()
        
        if risk_score >= 9.0:
            return "P0 - Emergency"
        elif risk_score >= 7.0:
            return "P1 - Critical"
        elif risk_score >= 5.0:
            return "P2 - High"
        elif risk_score >= 3.0:
            return "P3 - Medium"
        else:
            return "P4 - Low"
    
    def get_remediation_timeline(self) -> str:
        """Get expected remediation timeline based on priority"""
        priority = self.get_priority_level()
        
        timeline_map = {
            "P0 - Emergency": "Immediate (within 24 hours)",
            "P1 - Critical": "Urgent (within 72 hours)",
            "P2 - High": "Short-term (within 1 week)",
            "P3 - Medium": "Medium-term (within 1 month)",
            "P4 - Low": "Long-term (within 3 months)"
        }
        
        return timeline_map.get(priority, "Timeline not defined")

class VulnerabilityManager:
    def __init__(self):
        self.vulnerabilities: List[Vulnerability] = []
        self.remediation_tracking: Dict[str, Dict[str, Any]] = {}
    
    def load_vulnerabilities_from_scan(self, scan_file: str) -> None:
        """Load vulnerabilities from scan results"""
        try:
            with open(scan_file, 'r') as f:
                scan_data = json.load(f)
                
            # Process scan data based on format
            if 'vulnerabilities' in scan_data:  # Safety scan format
                for vuln_data in scan_data['vulnerabilities']:
                    vuln = Vulnerability(
                        cve_id=vuln_data.get('id', 'Unknown'),
                        title=vuln_data.get('advisory', 'Unknown Title'),
                        description=vuln_data.get('advisory', ''),
                        severity=Severity(vuln_data.get('severity', 'medium').lower()),
                        cvss_score=float(vuln_data.get('cvss', 0.0)),
                        affected_systems=vuln_data.get('affected_versions', []),
                        exploitability=self._assess_exploitability(vuln_data),
                        asset_criticality=self._assess_asset_criticality(vuln_data),
                        remediation_complexity=self._assess_remediation_complexity(vuln_data),
                        business_impact=self._assess_business_impact(vuln_data)
                    )
                    self.vulnerabilities.append(vuln)
                    
        except (FileNotFoundError, json.JSONDecodeError) as e:
            print(f"Error loading vulnerabilities from {scan_file}: {e}")
    
    def _assess_exploitability(self, vuln_data: Dict[str, Any]) -> Exploitability:
        """Assess exploitability based on vulnerability data"""
        # Simple heuristic - can be enhanced with more sophisticated logic
        cvss_score = float(vuln_data.get('cvss', 0.0))
        
        if cvss_score >= 8.0:
            return Exploitability.EASY
        elif cvss_score >= 5.0:
            return Exploitability.MEDIUM
        else:
            return Exploitability.HARD
    
    def _assess_asset_criticality(self, vuln_data: Dict[str, Any]) -> AssetCriticality:
        """Assess asset criticality based on affected systems"""
        affected_versions = vuln_data.get('affected_versions', [])
        
        # Check if critical systems are affected
        critical_indicators = ['proxmox', 'production', 'database', 'auth']
        
        for indicator in critical_indicators:
            for version in affected_versions:
                if indicator.lower() in str(version).lower():
                    return AssetCriticality.CRITICAL
        
        return AssetCriticality.MEDIUM  # Default to medium
    
    def _assess_remediation_complexity(self, vuln_data: Dict[str, Any]) -> str:
        """Assess remediation complexity"""
        # Simple assessment - can be enhanced
        if 'patch' in str(vuln_data).lower():
            return "Low - Patch available"
        elif 'update' in str(vuln_data).lower():
            return "Medium - Update required"
        else:
            return "High - Configuration change or workaround needed"
    
    def _assess_business_impact(self, vuln_data: Dict[str, Any]) -> str:
        """Assess potential business impact"""
        severity = vuln_data.get('severity', 'medium').lower()
        
        impact_map = {
            'critical': 'Service outage, data breach, regulatory compliance violation',
            'high': 'Service degradation, potential data exposure',
            'medium': 'Limited service impact, security control bypass',
            'low': 'Minimal impact, informational'
        }
        
        return impact_map.get(severity, 'Impact assessment needed')
    
    def generate_remediation_plan(self) -> Dict[str, Any]:
        """Generate comprehensive remediation plan"""
        # Sort vulnerabilities by risk score
        sorted_vulns = sorted(self.vulnerabilities, 
                             key=lambda v: v.calculate_risk_score(), 
                             reverse=True)
        
        plan = {
            "generated_at": datetime.now().isoformat(),
            "total_vulnerabilities": len(sorted_vulns),
            "priority_breakdown": {},
            "remediation_phases": [],
            "resource_requirements": {},
            "timeline": {}
        }
        
        # Group by priority
        priority_groups = {}
        for vuln in sorted_vulns:
            priority = vuln.get_priority_level()
            if priority not in priority_groups:
                priority_groups[priority] = []
            priority_groups[priority].append(vuln)
        
        plan["priority_breakdown"] = {
            priority: len(vulns) for priority, vulns in priority_groups.items()
        }
        
        # Create remediation phases
        phase_number = 1
        for priority in ["P0 - Emergency", "P1 - Critical", "P2 - High", "P3 - Medium", "P4 - Low"]:
            if priority in priority_groups:
                phase = {
                    "phase": phase_number,
                    "priority": priority,
                    "vulnerabilities": len(priority_groups[priority]),
                    "timeline": priority_groups[priority][0].get_remediation_timeline(),
                    "actions": [
                        {
                            "cve_id": vuln.cve_id,
                            "title": vuln.title,
                            "risk_score": vuln.calculate_risk_score(),
                            "affected_systems": vuln.affected_systems,
                            "remediation_complexity": vuln.remediation_complexity,
                            "business_impact": vuln.business_impact
                        }
                        for vuln in priority_groups[priority]
                    ]
                }
                plan["remediation_phases"].append(phase)
                phase_number += 1
        
        return plan
    
    def save_remediation_plan(self, plan: Dict[str, Any], filename: str) -> None:
        """Save remediation plan to file"""
        with open(filename, 'w') as f:
            json.dump(plan, f, indent=2)
        
        print(f"Remediation plan saved to: {filename}")

def main():
    if len(sys.argv) < 2:
        print("Usage: python vulnerability_risk_assessment.py <scan_results_file>")
        sys.exit(1)
    
    scan_file = sys.argv[1]
    
    # Create vulnerability manager
    vm = VulnerabilityManager()
    
    # Load vulnerabilities from scan
    vm.load_vulnerabilities_from_scan(scan_file)
    
    if not vm.vulnerabilities:
        print("No vulnerabilities found in scan results.")
        return
    
    # Generate remediation plan
    plan = vm.generate_remediation_plan()
    
    # Save plan
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"vulnerability_remediation_plan_{timestamp}.json"
    vm.save_remediation_plan(plan, filename)
    
    # Print summary
    print("\n=== Vulnerability Assessment Summary ===")
    print(f"Total vulnerabilities: {plan['total_vulnerabilities']}")
    print("\nPriority breakdown:")
    for priority, count in plan['priority_breakdown'].items():
        print(f"  {priority}: {count}")
    
    print(f"\nRemediation phases: {len(plan['remediation_phases'])}")
    
    # Print immediate action items
    emergency_phase = next((phase for phase in plan['remediation_phases'] 
                           if phase['priority'] == 'P0 - Emergency'), None)
    if emergency_phase:
        print(f"\nðŸš¨ EMERGENCY ACTIONS REQUIRED ({emergency_phase['vulnerabilities']} vulnerabilities):")
        for action in emergency_phase['actions'][:5]:  # Show top 5
            print(f"  - {action['cve_id']}: {action['title']} (Risk: {action['risk_score']:.1f})")

if __name__ == "__main__":
    main()
```

### 3. Vulnerability Remediation Procedures

#### Patch Management Process

```bash
#!/bin/bash
# Automated patch management script
# File: /scripts/security/patch_management.sh

set -euo pipefail

PATCH_LOG="/var/log/security/patch_management.log"
MAINTENANCE_WINDOW="02:00"
PROXMOX_HOST="192.168.1.50"

log_message() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1" | tee -a "$PATCH_LOG"
}

check_maintenance_window() {
    current_time=$(date '+%H:%M')
    if [[ "$current_time" < "02:00" || "$current_time" > "04:00" ]]; then
        log_message "WARNING: Patching outside maintenance window (02:00-04:00)"
        read -p "Continue anyway? (y/N): " confirm
        if [[ "$confirm" != "y" && "$confirm" != "Y" ]]; then
            log_message "Patching cancelled by user"
            exit 0
        fi
    fi
}

create_system_backup() {
    log_message "Creating system backup before patching..."
    
    # Create VM snapshots
    ssh -i ~/.ssh/proxmox_ai_key -p 2849 root@"$PROXMOX_HOST" "
        for vmid in \$(qm list | grep -v VMID | awk '{print \$1}'); do
            log_message \"Creating snapshot for VM \$vmid\"
            qm snapshot \$vmid \"pre_patch_\$(date +%Y%m%d_%H%M%S)\" --description \"Pre-patch snapshot\"
        done
    "
    
    # Backup configuration files
    ssh -i ~/.ssh/proxmox_ai_key -p 2849 root@"$PROXMOX_HOST" "
        tar -czf /backup/system_config_backup_\$(date +%Y%m%d_%H%M%S).tar.gz \
            /etc /var/lib/vz/template /var/lib/vz/dump 2>/dev/null || true
    "
    
    log_message "System backup completed"
}

update_proxmox_host() {
    log_message "Starting Proxmox host update process..."
    
    ssh -i ~/.ssh/proxmox_ai_key -p 2849 root@"$PROXMOX_HOST" "
        # Update package lists
        apt update
        
        # Check for available updates
        available_updates=\$(apt list --upgradable 2>/dev/null | wc -l)
        echo \"Available updates: \$((available_updates - 1))\"
        
        if [[ \$available_updates -gt 1 ]]; then
            # Download updates first
            apt -d upgrade -y
            
            # Apply security updates first
            apt upgrade -y -o Dpkg::Options::=\"--force-confdef\" -o Dpkg::Options::=\"--force-confold\"
            
            # Update Proxmox packages
            apt dist-upgrade -y -o Dpkg::Options::=\"--force-confdef\" -o Dpkg::Options::=\"--force-confold\"
            
            # Clean up
            apt autoremove -y
            apt autoclean
            
            echo \"Updates completed successfully\"
        else
            echo \"No updates available\"
        fi
    " 2>&1 | tee -a "$PATCH_LOG"
}

update_application_dependencies() {
    log_message "Updating application dependencies..."
    
    cd /home/diszay-claudedev/projects/iac-ai-assistant
    
    # Update Python dependencies
    if [[ -f "requirements.txt" ]]; then
        log_message "Updating Python dependencies"
        pip install --upgrade -r requirements.txt 2>&1 | tee -a "$PATCH_LOG"
    fi
    
    # Update development dependencies
    if [[ -f "requirements-dev.txt" ]]; then
        log_message "Updating development dependencies"
        pip install --upgrade -r requirements-dev.txt 2>&1 | tee -a "$PATCH_LOG"
    fi
    
    # Check for security vulnerabilities
    if command -v safety >/dev/null 2>&1; then
        log_message "Checking for security vulnerabilities in dependencies"
        safety check --json --output /tmp/safety_check_post_update.json || true
    fi
}

verify_system_integrity() {
    log_message "Verifying system integrity after updates..."
    
    # Test SSH connectivity
    if ssh -i ~/.ssh/proxmox_ai_key -p 2849 -o ConnectTimeout=10 root@"$PROXMOX_HOST" "echo 'SSH OK'"; then
        log_message "âœ“ SSH connectivity verified"
    else
        log_message "âœ— SSH connectivity failed"
        return 1
    fi
    
    # Test Proxmox API
    if curl -k -s -H "Authorization: PVEAPIToken=$PROXMOX_API_TOKEN" \
       https://192.168.1.50:8006/api2/json/version >/dev/null; then
        log_message "âœ“ Proxmox API connectivity verified"
    else
        log_message "âœ— Proxmox API connectivity failed"
        return 1
    fi
    
    # Test VM status
    ssh -i ~/.ssh/proxmox_ai_key -p 2849 root@"$PROXMOX_HOST" "
        failed_vms=0
        for vmid in \$(qm list | grep -v VMID | awk '{print \$1}'); do
            vm_status=\$(qm status \$vmid | grep -o 'status: [a-z]*' | cut -d' ' -f2)
            if [[ \"\$vm_status\" != \"running\" && \"\$vm_status\" != \"stopped\" ]]; then
                echo \"âœ— VM \$vmid status: \$vm_status\"
                ((failed_vms++))
            else
                echo \"âœ“ VM \$vmid status: \$vm_status\"
            fi
        done
        
        if [[ \$failed_vms -gt 0 ]]; then
            echo \"âœ— \$failed_vms VMs in unexpected state\"
            exit 1
        else
            echo \"âœ“ All VMs in expected state\"
        fi
    " 2>&1 | tee -a "$PATCH_LOG"
    
    # Test application functionality
    if /home/diszay-claudedev/projects/iac-ai-assistant/venv/bin/python -c "
        import sys
        sys.path.append('/home/diszay-claudedev/projects/iac-ai-assistant/src')
        try:
            from proxmox_ai.cli.main import app
            print('âœ“ Application imports successfully')
        except Exception as e:
            print(f'âœ— Application import failed: {e}')
            sys.exit(1)
    "; then
        log_message "âœ“ Application functionality verified"
    else
        log_message "âœ— Application functionality failed"
        return 1
    fi
    
    log_message "System integrity verification completed successfully"
}

send_patch_report() {
    log_message "Generating patch report..."
    
    # Create patch report
    cat << EOF > /tmp/patch_report_$(date +%Y%m%d).txt
Patch Management Report
Date: $(date)
System: Proxmox AI Infrastructure Assistant

=== Update Summary ===
$(tail -n 50 "$PATCH_LOG" | grep -E "(Updates completed|No updates available|dependencies updated)")

=== System Status ===
$(ssh -i ~/.ssh/proxmox_ai_key -p 2849 root@"$PROXMOX_HOST" "
    echo 'Proxmox Host Status:'
    pveversion
    echo ''
    echo 'VM Status:'
    qm list
    echo ''
    echo 'System Load:'
    uptime
    echo ''
    echo 'Disk Usage:'
    df -h | head -10
")

=== Security Status ===
$(if [[ -f "/tmp/safety_check_post_update.json" ]]; then
    python3 -c "
import json
with open('/tmp/safety_check_post_update.json', 'r') as f:
    data = json.load(f)
    vulns = data.get('vulnerabilities', [])
    print(f'Security vulnerabilities found: {len(vulns)}')
    if vulns:
        for vuln in vulns[:5]:  # Show top 5
            print(f'  - {vuln.get(\"advisory\", \"Unknown\")}: {vuln.get(\"severity\", \"Unknown\")}')
"
fi)

=== Recommendations ===
$(if [[ -f "/tmp/safety_check_post_update.json" ]]; then
    echo "- Review and address remaining security vulnerabilities"
fi)
- Monitor system performance for next 24 hours
- Verify all applications function correctly
- Schedule next maintenance window

Report generated on: $(date)
EOF
    
    log_message "Patch report generated: /tmp/patch_report_$(date +%Y%m%d).txt"
    
    # Send report via email if configured
    if command -v mail >/dev/null 2>&1 && [[ -n "${ADMIN_EMAIL:-}" ]]; then
        mail -s "Patch Management Report - $(date +%Y-%m-%d)" "$ADMIN_EMAIL" < /tmp/patch_report_$(date +%Y%m%d).txt
        log_message "Patch report sent to: $ADMIN_EMAIL"
    fi
}

rollback_changes() {
    log_message "Rolling back changes due to verification failure..."
    
    # Revert VM snapshots
    ssh -i ~/.ssh/proxmox_ai_key -p 2849 root@"$PROXMOX_HOST" "
        for vmid in \$(qm list | grep -v VMID | awk '{print \$1}'); do
            latest_snapshot=\$(qm listsnapshot \$vmid | grep 'pre_patch_' | tail -1 | awk '{print \$2}')
            if [[ -n \"\$latest_snapshot\" ]]; then
                log_message \"Reverting VM \$vmid to snapshot \$latest_snapshot\"
                qm rollback \$vmid \$latest_snapshot
            fi
        done
    "
    
    log_message "Rollback completed"
}

main() {
    log_message "Starting patch management process"
    
    # Check if running during maintenance window
    check_maintenance_window
    
    # Create system backup
    create_system_backup
    
    # Update systems
    update_proxmox_host
    update_application_dependencies
    
    # Verify system integrity
    if verify_system_integrity; then
        log_message "Patch management completed successfully"
        send_patch_report
    else
        log_message "System verification failed, initiating rollback"
        rollback_changes
        exit 1
    fi
}

# Handle script termination
trap 'log_message "Patch management interrupted"; exit 1' INT TERM

main "$@"
```

#### Emergency Patch Procedures

**For Critical/Zero-Day Vulnerabilities:**

1. **Immediate Assessment (0-30 minutes)**
   ```bash
   # Emergency vulnerability assessment
   VULN_ID="CVE-YYYY-NNNNN"
   
   # Check if system is affected
   ssh proxmox-ai "
       # Check installed packages
       dpkg -l | grep -i [affected_package]
       
       # Check running services
       systemctl list-units --state=running | grep -i [affected_service]
       
       # Check network exposure
       netstat -tulpn | grep [affected_port]
   "
   
   # Document findings
   echo "Emergency assessment for $VULN_ID: $(date)" >> /var/log/security/emergency_response.log
   ```

2. **Immediate Containment (0-60 minutes)**
   ```bash
   # If network service is affected, isolate immediately
   ssh proxmox-ai "
       # Block affected ports
       iptables -I INPUT -p tcp --dport [affected_port] -j DROP
       
       # Stop affected services
       systemctl stop [affected_service]
       
       # Disable service from starting
       systemctl disable [affected_service]
   "
   ```

3. **Emergency Patching (1-4 hours)**
   ```bash
   # Apply emergency patch
   ssh proxmox-ai "
       # Update package lists
       apt update
       
       # Apply specific security update
       apt install --only-upgrade [affected_package]
       
       # Restart affected services
       systemctl restart [affected_service]
       systemctl enable [affected_service]
   "
   
   # Remove temporary firewall rules
   ssh proxmox-ai "
       iptables -D INPUT -p tcp --dport [affected_port] -j DROP
   "
   ```

### 4. Vulnerability Tracking and Reporting

#### Vulnerability Database Schema

```sql
-- Vulnerability tracking database schema
-- File: /database/vulnerability_tracking.sql

CREATE TABLE vulnerabilities (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    cve_id VARCHAR(20) NOT NULL UNIQUE,
    title TEXT NOT NULL,
    description TEXT,
    severity VARCHAR(10) NOT NULL,
    cvss_score REAL,
    affected_systems TEXT, -- JSON array
    discovery_date DATE NOT NULL,
    status VARCHAR(20) DEFAULT 'open',
    assigned_to VARCHAR(100),
    remediation_plan TEXT,
    remediation_date DATE,
    verification_date DATE,
    notes TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE TABLE vulnerability_scans (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    scan_date DATE NOT NULL,
    scan_type VARCHAR(50) NOT NULL,
    total_vulnerabilities INTEGER,
    critical_count INTEGER DEFAULT 0,
    high_count INTEGER DEFAULT 0,
    medium_count INTEGER DEFAULT 0,
    low_count INTEGER DEFAULT 0,
    scan_duration INTEGER, -- seconds
    scan_results_path TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE TABLE remediation_activities (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    vulnerability_id INTEGER NOT NULL,
    activity_type VARCHAR(50) NOT NULL, -- 'patch', 'workaround', 'mitigation'
    description TEXT NOT NULL,
    performed_by VARCHAR(100) NOT NULL,
    activity_date DATE NOT NULL,
    success BOOLEAN DEFAULT FALSE,
    verification_notes TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (vulnerability_id) REFERENCES vulnerabilities(id)
);

-- Indexes for performance
CREATE INDEX idx_vulnerabilities_cve ON vulnerabilities(cve_id);
CREATE INDEX idx_vulnerabilities_status ON vulnerabilities(status);
CREATE INDEX idx_vulnerabilities_severity ON vulnerabilities(severity);
CREATE INDEX idx_scan_date ON vulnerability_scans(scan_date);
```

#### Vulnerability Reporting Dashboard

```python
#!/usr/bin/env python3
# Vulnerability reporting dashboard
# File: /scripts/security/vulnerability_dashboard.py

import sqlite3
import json
from datetime import datetime, timedelta
from typing import Dict, List, Any
import matplotlib.pyplot as plt
import seaborn as sns
from dataclasses import dataclass

@dataclass
class VulnerabilityMetrics:
    total_vulnerabilities: int
    open_vulnerabilities: int
    closed_vulnerabilities: int
    critical_count: int
    high_count: int
    medium_count: int
    low_count: int
    avg_remediation_time: float
    overdue_count: int

class VulnerabilityDashboard:
    def __init__(self, db_path: str = "/var/lib/security/vulnerabilities.db"):
        self.db_path = db_path
        self.conn = sqlite3.connect(db_path)
        self.conn.row_factory = sqlite3.Row
    
    def get_vulnerability_metrics(self) -> VulnerabilityMetrics:
        """Get current vulnerability metrics"""
        cursor = self.conn.cursor()
        
        # Total vulnerabilities
        cursor.execute("SELECT COUNT(*) FROM vulnerabilities")
        total = cursor.fetchone()[0]
        
        # Open/Closed counts
        cursor.execute("SELECT status, COUNT(*) FROM vulnerabilities GROUP BY status")
        status_counts = dict(cursor.fetchall())
        
        # Severity counts
        cursor.execute("SELECT severity, COUNT(*) FROM vulnerabilities WHERE status = 'open' GROUP BY severity")
        severity_counts = dict(cursor.fetchall())
        
        # Average remediation time
        cursor.execute("""
            SELECT AVG(julianday(remediation_date) - julianday(discovery_date)) as avg_days
            FROM vulnerabilities 
            WHERE status = 'closed' AND remediation_date IS NOT NULL
        """)
        avg_remediation = cursor.fetchone()[0] or 0
        
        # Overdue vulnerabilities (>30 days for critical, >90 days for others)
        cursor.execute("""
            SELECT COUNT(*) FROM vulnerabilities 
            WHERE status = 'open' AND (
                (severity = 'critical' AND julianday('now') - julianday(discovery_date) > 30) OR
                (severity != 'critical' AND julianday('now') - julianday(discovery_date) > 90)
            )
        """)
        overdue = cursor.fetchone()[0]
        
        return VulnerabilityMetrics(
            total_vulnerabilities=total,
            open_vulnerabilities=status_counts.get('open', 0),
            closed_vulnerabilities=status_counts.get('closed', 0),
            critical_count=severity_counts.get('critical', 0),
            high_count=severity_counts.get('high', 0),
            medium_count=severity_counts.get('medium', 0),
            low_count=severity_counts.get('low', 0),
            avg_remediation_time=avg_remediation,
            overdue_count=overdue
        )
    
    def generate_trend_report(self, days: int = 30) -> Dict[str, Any]:
        """Generate vulnerability trend report"""
        cursor = self.conn.cursor()
        start_date = datetime.now() - timedelta(days=days)
        
        # Daily vulnerability counts
        cursor.execute("""
            SELECT DATE(scan_date) as date,
                   SUM(critical_count) as critical,
                   SUM(high_count) as high,
                   SUM(medium_count) as medium,
                   SUM(low_count) as low,
                   SUM(total_vulnerabilities) as total
            FROM vulnerability_scans 
            WHERE scan_date >= ?
            GROUP BY DATE(scan_date)
            ORDER BY date
        """, (start_date.strftime('%Y-%m-%d'),))
        
        trend_data = [dict(row) for row in cursor.fetchall()]
        
        # Remediation activity
        cursor.execute("""
            SELECT DATE(activity_date) as date,
                   COUNT(*) as remediations,
                   SUM(CASE WHEN success = 1 THEN 1 ELSE 0 END) as successful
            FROM remediation_activities
            WHERE activity_date >= ?
            GROUP BY DATE(activity_date)
            ORDER BY date
        """, (start_date.strftime('%Y-%m-%d'),))
        
        remediation_data = [dict(row) for row in cursor.fetchall()]
        
        return {
            'period_days': days,
            'vulnerability_trends': trend_data,
            'remediation_trends': remediation_data,
            'generated_at': datetime.now().isoformat()
        }
    
    def generate_compliance_report(self) -> Dict[str, Any]:
        """Generate compliance report"""
        cursor = self.conn.cursor()
        
        # SLA compliance metrics
        cursor.execute("""
            SELECT 
                severity,
                COUNT(*) as total,
                SUM(CASE 
                    WHEN status = 'closed' AND 
                         ((severity = 'critical' AND julianday(remediation_date) - julianday(discovery_date) <= 1) OR
                          (severity = 'high' AND julianday(remediation_date) - julianday(discovery_date) <= 7) OR
                          (severity = 'medium' AND julianday(remediation_date) - julianday(discovery_date) <= 30) OR
                          (severity = 'low' AND julianday(remediation_date) - julianday(discovery_date) <= 90))
                    THEN 1 ELSE 0 END) as sla_compliant
            FROM vulnerabilities 
            WHERE discovery_date >= date('now', '-90 days')
            GROUP BY severity
        """)
        
        sla_data = [dict(row) for row in cursor.fetchall()]
        
        # Calculate overall compliance percentage
        total_vulns = sum(row['total'] for row in sla_data)
        total_compliant = sum(row['sla_compliant'] for row in sla_data)
        overall_compliance = (total_compliant / total_vulns * 100) if total_vulns > 0 else 100
        
        return {
            'reporting_period': '90 days',
            'overall_compliance_percentage': round(overall_compliance, 2),
            'sla_compliance_by_severity': sla_data,
            'sla_requirements': {
                'critical': '24 hours',
                'high': '7 days',
                'medium': '30 days',
                'low': '90 days'
            },
            'generated_at': datetime.now().isoformat()
        }
    
    def create_dashboard_charts(self, output_dir: str = "/var/www/html/security") -> None:
        """Create dashboard charts"""
        import matplotlib
        matplotlib.use('Agg')  # Use non-interactive backend
        
        metrics = self.get_vulnerability_metrics()
        
        # Vulnerability by severity pie chart
        plt.figure(figsize=(10, 6))
        
        plt.subplot(1, 2, 1)
        severity_data = [
            metrics.critical_count,
            metrics.high_count,
            metrics.medium_count,
            metrics.low_count
        ]
        severity_labels = ['Critical', 'High', 'Medium', 'Low']
        colors = ['#FF6B6B', '#FF8E53', '#4ECDC4', '#45B7D1']
        
        plt.pie(severity_data, labels=severity_labels, colors=colors, autopct='%1.1f%%')
        plt.title('Open Vulnerabilities by Severity')
        
        # Vulnerability status bar chart
        plt.subplot(1, 2, 2)
        status_data = [metrics.open_vulnerabilities, metrics.closed_vulnerabilities]
        status_labels = ['Open', 'Closed']
        colors = ['#FF6B6B', '#4ECDC4']
        
        plt.bar(status_labels, status_data, color=colors)
        plt.title('Vulnerability Status')
        plt.ylabel('Count')
        
        plt.tight_layout()
        plt.savefig(f"{output_dir}/vulnerability_overview.png", dpi=300, bbox_inches='tight')
        plt.close()
        
        # Trend chart
        trend_data = self.generate_trend_report(30)
        if trend_data['vulnerability_trends']:
            plt.figure(figsize=(12, 6))
            
            dates = [item['date'] for item in trend_data['vulnerability_trends']]
            critical = [item['critical'] for item in trend_data['vulnerability_trends']]
            high = [item['high'] for item in trend_data['vulnerability_trends']]
            medium = [item['medium'] for item in trend_data['vulnerability_trends']]
            low = [item['low'] for item in trend_data['vulnerability_trends']]
            
            plt.plot(dates, critical, label='Critical', color='#FF6B6B', linewidth=2)
            plt.plot(dates, high, label='High', color='#FF8E53', linewidth=2)
            plt.plot(dates, medium, label='Medium', color='#4ECDC4', linewidth=2)
            plt.plot(dates, low, label='Low', color='#45B7D1', linewidth=2)
            
            plt.title('Vulnerability Trends (30 Days)')
            plt.xlabel('Date')
            plt.ylabel('Count')
            plt.legend()
            plt.xticks(rotation=45)
            plt.grid(True, alpha=0.3)
            
            plt.tight_layout()
            plt.savefig(f"{output_dir}/vulnerability_trends.png", dpi=300, bbox_inches='tight')
            plt.close()
    
    def generate_executive_summary(self) -> str:
        """Generate executive summary report"""
        metrics = self.get_vulnerability_metrics()
        compliance = self.generate_compliance_report()
        
        summary = f"""
# Vulnerability Management Executive Summary
**Report Date**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## Current Status
- **Total Vulnerabilities**: {metrics.total_vulnerabilities}
- **Open Vulnerabilities**: {metrics.open_vulnerabilities}
- **Closed Vulnerabilities**: {metrics.closed_vulnerabilities}

## Risk Profile
- **Critical**: {metrics.critical_count} (Immediate attention required)
- **High**: {metrics.high_count} (Address within 7 days)
- **Medium**: {metrics.medium_count} (Address within 30 days)
- **Low**: {metrics.low_count} (Address within 90 days)

## Performance Metrics
- **Average Remediation Time**: {metrics.avg_remediation_time:.1f} days
- **Overdue Vulnerabilities**: {metrics.overdue_count}
- **SLA Compliance**: {compliance['overall_compliance_percentage']}%

## Key Recommendations
"""
        
        if metrics.critical_count > 0:
            summary += f"- **URGENT**: Address {metrics.critical_count} critical vulnerabilities immediately\n"
        
        if metrics.overdue_count > 0:
            summary += f"- Review and expedite {metrics.overdue_count} overdue vulnerabilities\n"
        
        if compliance['overall_compliance_percentage'] < 95:
            summary += f"- Improve SLA compliance from {compliance['overall_compliance_percentage']}% to >95%\n"
        
        summary += f"- Continue regular vulnerability scanning and monitoring\n"
        summary += f"- Maintain current security hardening practices\n"
        
        return summary

def main():
    dashboard = VulnerabilityDashboard()
    
    # Generate reports
    metrics = dashboard.get_vulnerability_metrics()
    print(f"Current vulnerability status: {metrics.open_vulnerabilities} open, {metrics.closed_vulnerabilities} closed")
    
    # Create dashboard charts
    dashboard.create_dashboard_charts()
    
    # Generate executive summary
    summary = dashboard.generate_executive_summary()
    with open("/tmp/vulnerability_executive_summary.md", "w") as f:
        f.write(summary)
    
    print("Dashboard reports generated successfully")

if __name__ == "__main__":
    main()
```

## Compliance Integration

### CIS Controls Alignment

**Control 7: Continuous Vulnerability Management**
- Establish and maintain a vulnerability management process
- Address vulnerabilities in order of risk
- Deploy automated tools for vulnerability management
- Perform regular vulnerability assessments

### Implementation Checklist

- [ ] **Automated Vulnerability Scanning**
  - Daily dependency scans
  - Weekly system scans
  - Monthly comprehensive assessments
  - Continuous monitoring integration

- [ ] **Risk-Based Prioritization**
  - CVSS scoring integration
  - Asset criticality assessment
  - Exploitability analysis
  - Business impact evaluation

- [ ] **Remediation Tracking**
  - SLA-based remediation timelines
  - Progress tracking and reporting
  - Escalation procedures
  - Verification and validation

- [ ] **Reporting and Metrics**
  - Executive dashboards
  - Compliance reporting
  - Trend analysis
  - Performance metrics

---

**Classification**: Internal Use - Security Procedures
**Last Updated**: 2025-07-29
**Review Schedule**: Quarterly
**Approved By**: Security Team Lead
**Document Version**: 1.0